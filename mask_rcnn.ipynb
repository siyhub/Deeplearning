{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [" \n", "'''\n", "Koden under er tatt utgangspunkt i en offentlig kilde kode fra Kaggle. Det er relativt f\u00c3\u00a5 endringer, kun noen ekstra\n", "implementeringer vi s\u00c3\u00a5 som n\u00c3\u00b8dvendig, eksempelvis logging av resultater fra treningen.  \n", "Utgangspunkt for kode : https://www.kaggle.com/samlin001/mask-r-cnn-ship-detection-minimum-viable-model-1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Koden oppsummert: konfiguering av datasett, konfiguering av Mask-RCNN, augmentering, trening- og treningsresultater og validering. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "import numpy as np # lin\u00c3\u00a6r algebra<br>\n", "import pandas as pd # data prosessering<br>\n", "import matplotlib.pyplot as plt # plotting og bilde prosessering<br>\n", "from skimage.morphology import label<br>\n", "from skimage.data import imread<br>\n", "import os<br>\n", "import time<br>\n", "import sys<br>\n", "rosjekt konfiguering\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["TRAINING_VALIDATION_RATIO = 0.2 # Stor andel av treningssettet som skal brukes i valideringssettet\n", "WORKING_DIR = '/kaggle/working'\n", "INPUT_DIR = '/kaggle/input'\n", "OUTPUT_DIR = '/kaggle/output'\n", "LOGS_DIR = os.path.join(WORKING_DIR, \"logs\")\n", "TRAIN_DATA_PATH = os.path.join(INPUT_DIR, 'train_v2')\n", "TEST_DATA_PATH = os.path.join(INPUT_DIR, 'test_v2')\n", "SAMPLE_SUBMISSION_PATH = os.path.join(INPUT_DIR, 'sample_submission_v2.csv')\n", "TRAIN_SHIP_SEGMENTATIONS_PATH = os.path.join(INPUT_DIR, 'train_ship_segmentations_v2.csv')\n", "MASK_RCNN_PATH = os.path.join(WORKING_DIR, 'Mask_RCNN-master')\n", "COCO_WEIGHTS_PATH = os.path.join(WORKING_DIR, \"mask_rcnn_coco.h5\")\n", "SHIP_CLASS_NAME = 'ship'\n", "IMAGE_WIDTH = 768\n", "IMAGE_HEIGHT = 768\n", "SHAPE = (IMAGE_WIDTH, IMAGE_HEIGHT)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["test_ds = os.listdir(TEST_DATA_PATH)\n", "train_ds = os.listdir(TRAIN_DATA_PATH)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Working Dir:', WORKING_DIR, os.listdir(WORKING_DIR))\n", "print('Input Dir:', INPUT_DIR, os.listdir(INPUT_DIR))\n", "print('train dataset from: {}, {}'.format(TRAIN_DATA_PATH, len(train_ds)))\n", "print('test dataset from: {}, {}'.format(TRAIN_DATA_PATH, len(test_ds)))\n", "print(TRAIN_SHIP_SEGMENTATIONS_PATH)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\nPreparering av datasett\n<br>\n", "# Leser maske koordninater fra CSV filen<br>\n", "masks = pd.read_csv(TRAIN_SHIP_SEGMENTATIONS_PATH)<br>\n", "masks.head()<br>\n", "# ref: https://www.kaggle.com/kmader/baseline-u-net-model-part-1<br>\n", "def multi_rle_encode(img):<br>\n", "    labels = label(img[:, :, 0])<br>\n", "    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]<br>\n", "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode<br>\n", "def rle_encode(img):<br>\n", "  \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    bilde: numpy array, 1 - mask, 0 - background\n", "    Returner lengden som et string format: [start0] [length0] [start1] [length1]... 1d array\n", "    '''\n", "    # omforming til 1d array\n", "    pixels = img.T.flatten() \n", "    \n", "    pixels = np.concatenate([[0], pixels, [0]])\n", "    \n", "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n", "  \n", "    runs[1::2] -= runs[::2]\n", "    \n", "    return ' '.join(str(x) for x in runs)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def rle_decode(mask_rle, shape=SHAPE):\n", "    '''\n", "    mask_rle: lengden som et string format: [start0] [length0] [start1] [length1]... in 1d array\n", "    form: (height,width) p\u00c3\u00a5 arrayen som returneres\n", "    Returner numpy array som formen, 1 - mask, 0 - background\n", "    '''\n", "    s = mask_rle.split()\n", "    # Start og lengde i 1d array\n", "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0::2], s[1::2])]\n", "    starts -= 1\n", "    # 1d array\n", "    ends = starts + lengths\n", "    #Oppretter en tom maske\n", "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n", "    # setter piksel\n", "    for lo, hi in zip(starts, ends):\n", "        img[lo:hi] = 1\n", "    # omformer til et 2d array\n", "    return img.reshape(shape).T  "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def masks_as_image(in_mask_list, shape=SHAPE):\n", "    \n", "    '''Tar hver individuelle skips maske og lager en singel maske array for alle skipene'''\n", "    \n", "    all_masks = np.zeros(shape, dtype = np.int16)\n", "    # Hvis det er et eksempel(in_mask_list, list):\n", "    for mask in in_mask_list:\n", "        if isinstance(mask, str):\n", "            all_masks += rle_decode(mask)\n", "    return np.expand_dims(all_masks, -1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def shows_decode_encode(image_id, path=TRAIN_DATA_PATH):\n", "    \n", "    '''Viser bilde, maske og koded/dekodet resultat'''\n", "    \n", "    fig, axarr = plt.subplots(1, 3, figsize = (10, 5))\n", "    # bilde\n", "    img_0 = imread(os.path.join(path, image_id))\n", "    axarr[0].imshow(img_0)\n", "    axarr[0].set_title(image_id)\n", "    \n", "    # input maske\n", "    rle_1 = masks.query('ImageId==\"{}\"'.format(image_id))['EncodedPixels']\n", "    img_1 = masks_as_image(rle_1)\n", "    # 2d array (shape.h, sahpe.w)\n", "    axarr[1].imshow(img_1[:, :, 0])\n", "    axarr[1].set_title('Ship Mask')\n", "    \n", "    # kodet & dekodet maske\n", "    rle_2 = multi_rle_encode(img_1)\n", "    img_2 = masks_as_image(rle_2)\n", "    axarr[2].imshow(img_0)\n", "    axarr[2].imshow(img_2[:, :, 0], alpha=0.3)\n", "    axarr[2].set_title('Encoded & Decoded Mask')\n", "    plt.show()\n", "    print(image_id , ' Check Decoding->Encoding',\n", "          'RLE_0:', len(rle_1), '->',\n", "          'RLE_1:', len(rle_2))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Sjekker noen eksempler"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["shows_decode_encode('000155de5.jpg')\n", "shows_decode_encode('00003e153.jpg')\n", "print('It could be different when there is no mask.')\n", "shows_decode_encode('00021ddc3.jpg')\n", "print('It could be different when there are masks overlapped.')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\nSplitte datasett inn i test- og valideringssett\n<br>\n", "# Sjekker om en maske har et skip<br>\n", "masks['ships'] = masks['EncodedPixels'].map(lambda encoded_pixels: 1 if isinstance(encoded_pixels, str) else 0)<br>\n", "# summerer skipene i ImageId og skaper en unique image id/maske liste<br>\n", "start_time = time.time()<br>\n", "unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'})<br>\n", "unique_img_ids['RleMaskList'] = masks.groupby('ImageId')['EncodedPixels'].apply(list)<br>\n", "unique_img_ids = unique_img_ids.reset_index()<br>\n", "end_time = time.time() - start_time<br>\n", "print(\"unique_img_ids groupby took: {}\".format(end_time))<br>\n", "# Bare bilder med skip<br>\n", "unique_img_ids = unique_img_ids[unique_img_ids['ships'] > 0]<br>\n", "unique_img_ids['ships'].hist()<br>\n", "unique_img_ids.sample(3)<br>\n", "# del inn i trenings- og valideringsset<br>\n", "from sklearn.model_selection import train_test_split<br>\n", "train_ids, val_ids = train_test_split(unique_img_ids, <br>\n", "                 test_size = TRAINING_VALIDATION_RATIO, <br>\n", "                 stratify = unique_img_ids['ships'])<br>\n", "print(train_ids.shape[0], 'training masks')<br>\n", "print(val_ids.shape[0], 'validation masks')<br>\n", "train_ids['ships'].hist()<br>\n", "val_ids['ships'].hist()<br>\n", "ask-RCNN model\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["mportering av Mask-RCNN"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Hvis Mask_RCNN allerede eksisterer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["UPDATE_MASK_RCNN = False"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["os.chdir(WORKING_DIR)\n", "if UPDATE_MASK_RCNN:\n", "    !rm -rf {MASK_RCNN_PATH}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Last ned MASK-RCNN script til lokal fil"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if not os.path.exists(MASK_RCNN_PATH):\n", "    ! wget https://github.com/samlin001/Mask_RCNN/archive/master.zip -O Mask_RCNN-master.zip\n", "    ! unzip Mask_RCNN-master.zip 'Mask_RCNN-master/mrcnn/*'\n", "    ! rm Mask_RCNN-master.zip"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Importer Mask RCNN"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sys.path.append(MASK_RCNN_PATH)  # Finner versjonen i bibliotekt\n", "from mrcnn.config import Config\n", "from mrcnn import utils\n", "import mrcnn.model as modellib\n", "from mrcnn import visualize\n", "from mrcnn.model import log    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["ransformering av datasett"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class AirbusShipDetectionChallengeDataset(utils.Dataset):\n", "    \"\"\"Airbus Ship Detection Challenge Dataset\n", "    \"\"\"\n", "    def __init__(self, image_file_dir, ids, masks, image_width=IMAGE_WIDTH, image_height=IMAGE_HEIGHT):\n", "        super().__init__(self)\n", "        self.image_file_dir = image_file_dir\n", "        self.ids = ids\n", "        self.masks = masks\n", "        self.image_width = image_width\n", "        self.image_height = image_height\n", "        \n", "        # legge til klasser\n", "        self.add_class(SHIP_CLASS_NAME, 1, SHIP_CLASS_NAME)\n", "        self.load_dataset()\n", "        \n", "    def load_dataset(self):\n", "        \"\"\"Load dataset from the path\n", "        \"\"\"\n", "        # legge til bilder\n", "        for index, row in self.ids.iterrows():\n", "            image_id = row['ImageId']\n", "            image_path = os.path.join(self.image_file_dir, image_id)\n", "            rle_mask_list = row['RleMaskList']\n", "            #print(rle_mask_list)\n", "            self.add_image(\n", "                SHIP_CLASS_NAME,\n", "                image_id=image_id,\n", "                path=image_path,\n", "                width=self.image_width, height=self.image_height,\n", "                rle_mask_list=rle_mask_list)\n", "    def load_mask(self, image_id):\n", "        \"\"\"Genererer masker for former til gitt bilde ID\n", "        \"\"\"\n", "        info = self.image_info[image_id]\n", "        rle_mask_list = info['rle_mask_list']\n", "        mask_count = len(rle_mask_list)\n", "        mask = np.zeros([info['height'], info['width'], mask_count],\n", "                        dtype=np.uint8)\n", "        i = 0\n", "        for rel in rle_mask_list:\n", "            if isinstance(rel, str):\n", "                np.copyto(mask[:,:,i], rle_decode(rel))\n", "            i += 1\n", "        \n", "        # Returnerer masker, og en array av ider for hvert eksempel. Siden vi bare har\n", "        # en klasse IDer, returner vi en array av 1s\n", "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n", "    \n", "    def image_reference(self, image_id):\n", "        \"\"\"Returner filbanen til bilde.\"\"\"\n", "        info = self.image_info[image_id]\n", "        if info['source'] == SHIP_CLASS_NAME:\n", "            return info['path']\n", "        else:\n", "            super(self.__class__, self).image_reference(image_id)\n", "            "]}, {"cell_type": "markdown", "metadata": {}, "source": ["\nModel konfigurering. Vi setter kun de viktiste forh\u00c3\u00a5ndsbestemte parameterne, her er det mye pr\u00c3\u00b8ving og feiling for \u00c3\u00a5 finne de optimale.<br>\n", "rdiene satt her oversskriver de satte parameterne i config.py\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class AirbusShipDetectionChallengeGPUConfig(Config):\n", "   \n", "    # https://www.kaggle.com/docs/kernels#technical-specifications\n", "    NAME = 'ASDC_GPU'\n", "    # Antall GPUer.\n", "    GPU_COUNT = 1\n", "    IMAGES_PER_GPU = 4\n", "    \n", "    NUM_CLASSES = 2  # ship eller background\n", "    IMAGE_MIN_DIM = IMAGE_WIDTH\n", "    IMAGE_MAX_DIM = IMAGE_WIDTH\n", "    STEPS_PER_EPOCH = 300\n", "    VALIDATION_STEPS = 50\n", "    SAVE_BEST_ONLY = True\n", "    \n", "    # Minstekrav for deteksjon\n", "    # Alle deteksjoner under grensen blir droppet\n", "    DETECTION_MIN_CONFIDENCE = 0.90\n\n", "    #Grense for overlappende deteksjoner\n", "    DETECTION_NMS_THRESHOLD = 0.05\n", "    #Start verdier for vekter f\u00c3\u00b8r trening. Disse tilpasses underveis\n", "    LOSS_WEIGHTS = {\n", "        \"rpn_class_loss\": 30.0,\n", "        \"rpn_bbox_loss\": 0.8,\n", "        \"mrcnn_class_loss\": 6.0,\n", "        \"mrcnn_bbox_loss\": 1.0,\n", "        \"mrcnn_mask_loss\": 1.2\n", "    }\n", "    \n", "config = AirbusShipDetectionChallengeGPUConfig()\n", "config.display()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\nLaster inn datasettene \n<br>\n", "start_time = time.time()<br>\n", "# Treningsdatasett<br>\n", "dataset_train = AirbusShipDetectionChallengeDataset(image_file_dir=TRAIN_DATA_PATH, ids=train_ids, masks=masks)<br>\n", "dataset_train.prepare()<br>\n", "# Valideringssdataset<br>\n", "dataset_val = AirbusShipDetectionChallengeDataset(image_file_dir=TRAIN_DATA_PATH, ids=val_ids, masks=masks)<br>\n", "dataset_val.prepare()<br>\n", "# Vis tilfeldige eksempler<br>\n", "image_ids = np.random.choice(dataset_train.image_ids, 3)<br>\n", "for image_id in image_ids:<br>\n", "    image = dataset_train.load_image(image_id)<br>\n", "    mask, class_ids = dataset_train.load_mask(image_id)<br>\n", "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names, limit=1)<br>\n", "end_time = time.time() - start_time<br>\n", "print(\"dataset prepare: {}\".format(end_time))<br>\n", "verf\u00c3\u00b8rt l\u00c3\u00a6ring. Laster ned vekter som er trent p\u00c3\u00a5 datasettet MS COCO \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["start_time = time.time()\n", "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=WORKING_DIR)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import errno\n", "try:\n", "    weights_path = model.find_last()\n", "    load_weights = True\n", "except FileNotFoundError:\n", "    # Hvis det ikke er noen tidligere trente vekter, last ned MS COCO\n", "    load_weights = True\n", "    weights_path = COCO_WEIGHTS_PATH\n", "    utils.download_trained_weights(weights_path)\n", "    \n", "if load_weights:\n", "    print(\"Loading weights: \", weights_path)\n", "    model.load_weights(weights_path, by_name=True, exclude=[\n", "                \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n", "                \"mrcnn_bbox\", \"mrcnn_mask\"])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["end_time = time.time() - start_time\n", "print(\"loading weights: {}\".format(end_time))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\nKode for augmentering av datasettet\n<br>\n", "#Forh\u00c3\u00a5ndskonfigurering for augmentering<br>\n", "from skimage.io import imread<br>\n", "from matplotlib.cm import get_cmap<br>\n", "from skimage.segmentation import mark_boundaries<br>\n", "from skimage.util import montage<br>\n", "from skimage.morphology import binary_opening, disk, label<br>\n", "import gc; gc.enable() <br>\n", "from imgaug import augmenters as iaa<br>\n", "# Bilde augmentering<br>\n", "augmentation = iaa.Sequential([<br>\n", "    iaa.OneOf([ ## rotering<br>\n", "        iaa.Affine(rotate=0),<br>\n", "        iaa.Affine(rotate=90),<br>\n", "        iaa.Affine(rotate=180),<br>\n", "        iaa.Affine(rotate=270),<br>\n", "    ]),<br>\n", "    iaa.Fliplr(0.5),<br>\n", "    iaa.Flipud(0.5),<br>\n", "    iaa.OneOf([ ## lysstyrke eller kontrast<br>\n", "        iaa.Multiply((0.9, 1.1)),<br>\n", "        iaa.ContrastNormalization((0.9, 1.1)),<br>\n", "    ]),<br>\n", "    iaa.OneOf([ ## uskarpe og skarpe<br>\n", "        iaa.GaussianBlur(sigma=(0.0, 0.1)),<br>\n", "        iaa.Sharpen(alpha=(0.0, 0.1)),<br>\n", "    ]),<br>\n", "])<br>\n", "# Test p\u00c3\u00a5 det samme bilde som over<br>\n", "imggrid = augmentation.draw_grid(image, cols=5, rows=2)<br>\n", "plt.figure(figsize=(30, 12))<br>\n", "_ = plt.imshow(imggrid.astype(int))<br>\n", "rening av modellen\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["start_time = time.time()   "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.train(dataset_train, dataset_val,\n", "            learning_rate=config.LEARNING_RATE * 1.5,\n", "            epochs=40,\n", "            layers='all',\n", "            augmentation=augmentation)\n", "end_time = time.time() - start_time\n", "print(\"Train model: {}\".format(end_time))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["agrer viktig data om treningsresultatene"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["history = model.keras_model.history.history"]}, {"cell_type": "markdown", "metadata": {}, "source": ["kriver ut en tabell over treningsresultatene"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["epochs = range(1, len(history['loss'])+1)\n", "pd.DataFrame(history, index=epochs)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["kriver ut grafer over treningsresultatene"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(21,11))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.subplot(231)\n", "plt.plot(epochs, history[\"loss\"], label=\"Train loss\")\n", "plt.plot(epochs, history[\"val_loss\"], label=\"Valid loss\")\n", "plt.legend()\n", "plt.subplot(232)\n", "plt.plot(epochs, history[\"rpn_class_loss\"], label=\"Train RPN class ce\")\n", "plt.plot(epochs, history[\"val_rpn_class_loss\"], label=\"Valid RPN class ce\")\n", "plt.legend()\n", "plt.subplot(233)\n", "plt.plot(epochs, history[\"rpn_bbox_loss\"], label=\"Train RPN box loss\")\n", "plt.plot(epochs, history[\"val_rpn_bbox_loss\"], label=\"Valid RPN box loss\")\n", "plt.legend()\n", "plt.subplot(234)\n", "plt.plot(epochs, history[\"mrcnn_class_loss\"], label=\"Train MRCNN class ce\")\n", "plt.plot(epochs, history[\"val_mrcnn_class_loss\"], label=\"Valid MRCNN class ce\")\n", "plt.legend()\n", "plt.subplot(235)\n", "plt.plot(epochs, history[\"mrcnn_bbox_loss\"], label=\"Train MRCNN box loss\")\n", "plt.plot(epochs, history[\"val_mrcnn_bbox_loss\"], label=\"Valid MRCNN box loss\")\n", "plt.legend()\n", "plt.subplot(236)\n", "plt.plot(epochs, history[\"mrcnn_mask_loss\"], label=\"Train Mask loss\")\n", "plt.plot(epochs, history[\"val_mrcnn_mask_loss\"], label=\"Valid Mask loss\")\n", "plt.legend()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}